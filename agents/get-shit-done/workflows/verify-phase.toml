prompt = "<purpose>\nVerify phase goal achievement through goal-backward analysis. Check that the codebase actually delivers what the phase promised, not just that tasks were completed.\n\nThis workflow is executed by a verification subagent spawned from execute-phase.md.\n</purpose>\n\n<core_principle>\n**Task completion ‚â† Goal achievement**\n\nA task \"create chat component\" can be marked complete when the component is a placeholder. The task was done ‚Äî a file was created ‚Äî but the goal \"working chat interface\" was not achieved.\n\nGoal-backward verification starts from the outcome and works backwards:\n1. What must be TRUE for the goal to be achieved?\n2. What must EXIST for those truths to hold?\n3. What must be WIRED for those artifacts to function?\n\nThen verify each level against the actual codebase.\n</core_principle>\n\n<required_reading>\n@/Users/filipefernandes/.gemini/get-shit-done/references/verification-patterns.md\n@/Users/filipefernandes/.gemini/get-shit-done/templates/verification-report.md\n</required_reading>\n\n<process>\n\n<step name=\"load_context\" priority=\"first\">\n**Gather all verification context:**\n\n```bash\n# Phase directory (match both zero-padded and unpadded)\nPADDED_PHASE=$(printf \"%02d\" ${PHASE_ARG} 2>/dev/null || echo \"${PHASE_ARG}\")\nPHASE_DIR=$(ls -d .planning/phases/${PADDED_PHASE}-* .planning/phases/${PHASE_ARG}-* 2>/dev/null | head -1)\n\n# Phase goal from ROADMAP\ngrep -A 5 \"Phase ${PHASE_NUM}\" .planning/ROADMAP.md\n\n# Requirements mapped to this phase\ngrep -E \"^| ${PHASE_NUM}\" .planning/REQUIREMENTS.md 2>/dev/null\n\n# All SUMMARY files (claims to verify)\nls \"$PHASE_DIR\"/*-SUMMARY.md 2>/dev/null\n\n# All PLAN files (for must_haves in frontmatter)\nls \"$PHASE_DIR\"/*-PLAN.md 2>/dev/null\n```\n\n**Extract phase goal:** Parse ROADMAP.md for this phase's goal/description. This is the outcome to verify, not the tasks.\n\n**Extract requirements:** If REQUIREMENTS.md exists, find requirements mapped to this phase. These become additional verification targets.\n</step>\n\n<step name=\"establish_must_haves\">\n**Determine what must be verified.**\n\n**Option A: Must-haves in PLAN frontmatter**\n\nCheck if any PLAN.md has `must_haves` in frontmatter:\n\n```bash\ngrep -l \"must_haves:\" \"$PHASE_DIR\"/*-PLAN.md 2>/dev/null\n```\n\nIf found, extract and use:\n```yaml\nmust_haves:\n  truths:\n    - \"User can see existing messages\"\n    - \"User can send a message\"\n  artifacts:\n    - path: \"src/components/Chat.tsx\"\n      provides: \"Message list rendering\"\n  key_links:\n    - from: \"Chat.tsx\"\n      to: \"api/chat\"\n      via: \"fetch in useEffect\"\n```\n\n**Option B: Derive from phase goal**\n\nIf no must_haves in frontmatter, derive using goal-backward process:\n\n1. **State the goal:** Take phase goal from ROADMAP.md\n\n2. **Derive truths:** Ask \"What must be TRUE for this goal to be achieved?\"\n   - List 3-7 observable behaviors from user perspective\n   - Each truth should be testable by a human using the app\n\n3. **Derive artifacts:** For each truth, ask \"What must EXIST?\"\n   - Map truths to concrete files (components, routes, schemas)\n   - Be specific: `src/components/Chat.tsx`, not \"chat component\"\n\n4. **Derive key links:** For each artifact, ask \"What must be CONNECTED?\"\n   - Identify critical wiring (component calls API, API queries DB)\n   - These are where stubs hide\n\n5. **Document derived must-haves** before proceeding to verification.\n\n<!-- Goal-backward derivation expertise is baked into the gsd-verifier agent -->\n</step>\n\n<step name=\"verify_truths\">\n**For each observable truth, determine if codebase enables it.**\n\nA truth is achievable if the supporting artifacts exist, are substantive, and are wired correctly.\n\n**Verification status:**\n- ‚úì VERIFIED: All supporting artifacts pass all checks\n- ‚úó FAILED: One or more supporting artifacts missing, stub, or unwired\n- ? UNCERTAIN: Can't verify programmatically (needs human)\n\n**For each truth:**\n\n1. Identify supporting artifacts (which files make this truth possible?)\n2. Check artifact status (see verify_artifacts step)\n3. Check wiring status (see verify_wiring step)\n4. Determine truth status based on supporting infrastructure\n\n**Example:**\n\nTruth: \"User can see existing messages\"\n\nSupporting artifacts:\n- Chat.tsx (renders messages)\n- /api/chat GET (provides messages)\n- Message model (defines schema)\n\nIf Chat.tsx is a stub ‚Üí Truth FAILED\nIf /api/chat GET returns hardcoded [] ‚Üí Truth FAILED\nIf Chat.tsx exists, is substantive, calls API, renders response ‚Üí Truth VERIFIED\n</step>\n\n<step name=\"verify_artifacts\">\n**For each required artifact, verify three levels:**\n\n### Level 1: Existence\n\n```bash\ncheck_exists() {\n  local path=\"$1\"\n  if [ -f \"$path\" ]; then\n    echo \"EXISTS\"\n  elif [ -d \"$path\" ]; then\n    echo \"EXISTS (directory)\"\n  else\n    echo \"MISSING\"\n  fi\n}\n```\n\nIf MISSING ‚Üí artifact fails, record and continue to next artifact.\n\n### Level 2: Substantive\n\nCheck that the file has real implementation, not a stub.\n\n**Line count check:**\n```bash\ncheck_length() {\n  local path=\"$1\"\n  local min_lines=\"$2\"\n  local lines=$(wc -l < \"$path\" 2>/dev/null || echo 0)\n  [ \"$lines\" -ge \"$min_lines\" ] && echo \"SUBSTANTIVE ($lines lines)\" || echo \"THIN ($lines lines)\"\n}\n```\n\nMinimum lines by type:\n- Component: 15+ lines\n- API route: 10+ lines\n- Hook/util: 10+ lines\n- Schema model: 5+ lines\n\n**Stub pattern check:**\n```bash\ncheck_stubs() {\n  local path=\"$1\"\n\n  # Universal stub patterns\n  local stubs=$(grep -c -E \"TODO|FIXME|placeholder|not implemented|coming soon\" \"$path\" 2>/dev/null || echo 0)\n\n  # Empty returns\n  local empty=$(grep -c -E \"return null|return undefined|return \\{\\}|return \\[\\]\" \"$path\" 2>/dev/null || echo 0)\n\n  # Placeholder content\n  local placeholder=$(grep -c -E \"will be here|placeholder|lorem ipsum\" \"$path\" 2>/dev/null || echo 0)\n\n  local total=$((stubs + empty + placeholder))\n  [ \"$total\" -gt 0 ] && echo \"STUB_PATTERNS ($total found)\" || echo \"NO_STUBS\"\n}\n```\n\n**Export check (for components/hooks):**\n```bash\ncheck_exports() {\n  local path=\"$1\"\n  grep -E \"^export (default )?(function|const|class)\" \"$path\" && echo \"HAS_EXPORTS\" || echo \"NO_EXPORTS\"\n}\n```\n\n**Combine level 2 results:**\n- SUBSTANTIVE: Adequate length + no stubs + has exports\n- STUB: Too short OR has stub patterns OR no exports\n- PARTIAL: Mixed signals (length OK but has some stubs)\n\n### Level 3: Wired\n\nCheck that the artifact is connected to the system.\n\n**Import check (is it used?):**\n```bash\ncheck_imported() {\n  local artifact_name=\"$1\"\n  local search_path=\"${2:-src/}\"\n\n  # Find imports of this artifact\n  local imports=$(grep -r \"import.*$artifact_name\" \"$search_path\" --include=\"*.ts\" --include=\"*.tsx\" 2>/dev/null | wc -l)\n\n  [ \"$imports\" -gt 0 ] && echo \"IMPORTED ($imports times)\" || echo \"NOT_IMPORTED\"\n}\n```\n\n**Usage check (is it called?):**\n```bash\ncheck_used() {\n  local artifact_name=\"$1\"\n  local search_path=\"${2:-src/}\"\n\n  # Find usages (function calls, component renders, etc.)\n  local uses=$(grep -r \"$artifact_name\" \"$search_path\" --include=\"*.ts\" --include=\"*.tsx\" 2>/dev/null | grep -v \"import\" | wc -l)\n\n  [ \"$uses\" -gt 0 ] && echo \"USED ($uses times)\" || echo \"NOT_USED\"\n}\n```\n\n**Combine level 3 results:**\n- WIRED: Imported AND used\n- ORPHANED: Exists but not imported/used\n- PARTIAL: Imported but not used (or vice versa)\n\n### Final artifact status\n\n| Exists | Substantive | Wired | Status |\n|--------|-------------|-------|--------|\n| ‚úì | ‚úì | ‚úì | ‚úì VERIFIED |\n| ‚úì | ‚úì | ‚úó | ‚ö†Ô∏è ORPHANED |\n| ‚úì | ‚úó | - | ‚úó STUB |\n| ‚úó | - | - | ‚úó MISSING |\n\nRecord status and evidence for each artifact.\n</step>\n\n<step name=\"verify_wiring\">\n**Verify key links between artifacts.**\n\nKey links are critical connections. If broken, the goal fails even with all artifacts present.\n\n### Pattern: Component ‚Üí API\n\nCheck if component actually calls the API:\n\n```bash\nverify_component_api_link() {\n  local component=\"$1\"\n  local api_path=\"$2\"\n\n  # Check for fetch/axios call to the API\n  local has_call=$(grep -E \"fetch\\(['\\\"].*$api_path|axios\\.(get|post).*$api_path\" \"$component\" 2>/dev/null)\n\n  if [ -n \"$has_call\" ]; then\n    # Check if response is used\n    local uses_response=$(grep -A 5 \"fetch\\|axios\" \"$component\" | grep -E \"await|\\.then|setData|setState\" 2>/dev/null)\n\n    if [ -n \"$uses_response\" ]; then\n      echo \"WIRED: $component ‚Üí $api_path (call + response handling)\"\n    else\n      echo \"PARTIAL: $component ‚Üí $api_path (call exists but response not used)\"\n    fi\n  else\n    echo \"NOT_WIRED: $component ‚Üí $api_path (no call found)\"\n  fi\n}\n```\n\n### Pattern: API ‚Üí Database\n\nCheck if API route queries database:\n\n```bash\nverify_api_db_link() {\n  local route=\"$1\"\n  local model=\"$2\"\n\n  # Check for Prisma/DB call\n  local has_query=$(grep -E \"prisma\\.$model|db\\.$model|$model\\.(find|create|update|delete)\" \"$route\" 2>/dev/null)\n\n  if [ -n \"$has_query\" ]; then\n    # Check if result is returned\n    local returns_result=$(grep -E \"return.*json.*\\w+|res\\.json\\(\\w+\" \"$route\" 2>/dev/null)\n\n    if [ -n \"$returns_result\" ]; then\n      echo \"WIRED: $route ‚Üí database ($model)\"\n    else\n      echo \"PARTIAL: $route ‚Üí database (query exists but result not returned)\"\n    fi\n  else\n    echo \"NOT_WIRED: $route ‚Üí database (no query for $model)\"\n  fi\n}\n```\n\n### Pattern: Form ‚Üí Handler\n\nCheck if form submission does something:\n\n```bash\nverify_form_handler_link() {\n  local component=\"$1\"\n\n  # Find onSubmit handler\n  local has_handler=$(grep -E \"onSubmit=\\{|handleSubmit\" \"$component\" 2>/dev/null)\n\n  if [ -n \"$has_handler\" ]; then\n    # Check if handler has real implementation\n    local handler_content=$(grep -A 10 \"onSubmit.*=\" \"$component\" | grep -E \"fetch|axios|mutate|dispatch\" 2>/dev/null)\n\n    if [ -n \"$handler_content\" ]; then\n      echo \"WIRED: form ‚Üí handler (has API call)\"\n    else\n      # Check for stub patterns\n      local is_stub=$(grep -A 5 \"onSubmit\" \"$component\" | grep -E \"console\\.log|preventDefault\\(\\)$|\\{\\}\" 2>/dev/null)\n      if [ -n \"$is_stub\" ]; then\n        echo \"STUB: form ‚Üí handler (only logs or empty)\"\n      else\n        echo \"PARTIAL: form ‚Üí handler (exists but unclear implementation)\"\n      fi\n    fi\n  else\n    echo \"NOT_WIRED: form ‚Üí handler (no onSubmit found)\"\n  fi\n}\n```\n\n### Pattern: State ‚Üí Render\n\nCheck if state is actually rendered:\n\n```bash\nverify_state_render_link() {\n  local component=\"$1\"\n  local state_var=\"$2\"\n\n  # Check if state variable exists\n  local has_state=$(grep -E \"useState.*$state_var|\\[$state_var,\" \"$component\" 2>/dev/null)\n\n  if [ -n \"$has_state\" ]; then\n    # Check if state is used in JSX\n    local renders_state=$(grep -E \"\\{.*$state_var.*\\}|\\{$state_var\\.\" \"$component\" 2>/dev/null)\n\n    if [ -n \"$renders_state\" ]; then\n      echo \"WIRED: state ‚Üí render ($state_var displayed)\"\n    else\n      echo \"NOT_WIRED: state ‚Üí render ($state_var exists but not displayed)\"\n    fi\n  else\n    echo \"N/A: state ‚Üí render (no state var $state_var)\"\n  fi\n}\n```\n\n### Aggregate key link results\n\nFor each key link in must_haves:\n- Run appropriate verification function\n- Record status and evidence\n- WIRED / PARTIAL / STUB / NOT_WIRED\n</step>\n\n<step name=\"verify_requirements\">\n**Check requirements coverage if REQUIREMENTS.md exists.**\n\n```bash\n# Find requirements mapped to this phase\ngrep -E \"Phase ${PHASE_NUM}\" .planning/REQUIREMENTS.md 2>/dev/null\n```\n\nFor each requirement:\n1. Parse requirement description\n2. Identify which truths/artifacts support it\n3. Determine status based on supporting infrastructure\n\n**Requirement status:**\n- ‚úì SATISFIED: All supporting truths verified\n- ‚úó BLOCKED: One or more supporting truths failed\n- ? NEEDS HUMAN: Can't verify requirement programmatically\n</step>\n\n<step name=\"scan_antipatterns\">\n**Scan for anti-patterns across phase files.**\n\nIdentify files modified in this phase:\n```bash\n# Extract files from SUMMARY.md\ngrep -E \"^\\- \\`\" \"$PHASE_DIR\"/*-SUMMARY.md | sed 's/.*`\\([^`]*\\)`.*/\\1/' | sort -u\n```\n\nRun anti-pattern detection:\n```bash\nscan_antipatterns() {\n  local files=\"$@\"\n\n  echo \"## Anti-Patterns Found\"\n  echo \"\"\n\n  for file in $files; do\n    [ -f \"$file\" ] || continue\n\n    # TODO/FIXME comments\n    grep -n -E \"TODO|FIXME|XXX|HACK\" \"$file\" 2>/dev/null | while read line; do\n      echo \"| $file | $(echo $line | cut -d: -f1) | TODO/FIXME | ‚ö†Ô∏è Warning |\"\n    done\n\n    # Placeholder content\n    grep -n -E \"placeholder|coming soon|will be here\" \"$file\" -i 2>/dev/null | while read line; do\n      echo \"| $file | $(echo $line | cut -d: -f1) | Placeholder | üõë Blocker |\"\n    done\n\n    # Empty implementations\n    grep -n -E \"return null|return \\{\\}|return \\[\\]|=> \\{\\}\" \"$file\" 2>/dev/null | while read line; do\n      echo \"| $file | $(echo $line | cut -d: -f1) | Empty return | ‚ö†Ô∏è Warning |\"\n    done\n\n    # Console.log only implementations\n    grep -n -B 2 -A 2 \"console\\.log\" \"$file\" 2>/dev/null | grep -E \"^\\s*(const|function|=>)\" | while read line; do\n      echo \"| $file | - | Log-only function | ‚ö†Ô∏è Warning |\"\n    done\n  done\n}\n```\n\nCategorize findings:\n- üõë Blocker: Prevents goal achievement (placeholder renders, empty handlers)\n- ‚ö†Ô∏è Warning: Indicates incomplete (TODO comments, console.log)\n- ‚ÑπÔ∏è Info: Notable but not problematic\n</step>\n\n<step name=\"identify_human_verification\">\n**Flag items that need human verification.**\n\nSome things can't be verified programmatically:\n\n**Always needs human:**\n- Visual appearance (does it look right?)\n- User flow completion (can you do the full task?)\n- Real-time behavior (WebSocket, SSE updates)\n- External service integration (payments, email)\n- Performance feel (does it feel fast?)\n- Error message clarity\n\n**Needs human if uncertain:**\n- Complex wiring that grep can't trace\n- Dynamic behavior depending on state\n- Edge cases and error states\n\n**Format for human verification:**\n```markdown\n## Human Verification Required\n\n### 1. {Test Name}\n**Test:** {What to do}\n**Expected:** {What should happen}\n**Why human:** {Why can't verify programmatically}\n```\n</step>\n\n<step name=\"determine_status\">\n**Calculate overall verification status.**\n\n**Status: passed**\n- All truths VERIFIED\n- All artifacts pass level 1-3\n- All key links WIRED\n- No blocker anti-patterns\n- (Human verification items are OK ‚Äî will be prompted)\n\n**Status: gaps_found**\n- One or more truths FAILED\n- OR one or more artifacts MISSING/STUB\n- OR one or more key links NOT_WIRED\n- OR blocker anti-patterns found\n\n**Status: human_needed**\n- All automated checks pass\n- BUT items flagged for human verification\n- Can't determine goal achievement without human\n\n**Calculate score:**\n```\nscore = (verified_truths / total_truths)\n```\n</step>\n\n<step name=\"generate_fix_plans\">\n**If gaps_found, recommend fix plans.**\n\nGroup related gaps into fix plans:\n\n1. **Identify gap clusters:**\n   - API stub + component not wired ‚Üí \"Wire frontend to backend\"\n   - Multiple artifacts missing ‚Üí \"Complete core implementation\"\n   - Wiring issues only ‚Üí \"Connect existing components\"\n\n2. **Generate plan recommendations:**\n\n```markdown\n### {phase}-{next}-PLAN.md: {Fix Name}\n\n**Objective:** {What this fixes}\n\n**Tasks:**\n1. {Task to fix gap 1}\n   - Files: {files to modify}\n   - Action: {specific fix}\n   - Verify: {how to confirm fix}\n\n2. {Task to fix gap 2}\n   - Files: {files to modify}\n   - Action: {specific fix}\n   - Verify: {how to confirm fix}\n\n3. Re-verify phase goal\n   - Run verification again\n   - Confirm all must-haves pass\n\n**Estimated scope:** {Small / Medium}\n```\n\n3. **Keep plans focused:**\n   - 2-3 tasks per plan\n   - Single concern per plan\n   - Include verification task\n\n4. **Order by dependency:**\n   - Fix missing artifacts before wiring\n   - Fix stubs before integration\n   - Verify after all fixes\n</step>\n\n<step name=\"create_report\">\n**Generate VERIFICATION.md using template.**\n\n```bash\nREPORT_PATH=\"$PHASE_DIR/${PHASE_NUM}-VERIFICATION.md\"\n```\n\nFill template sections:\n1. **Frontmatter:** phase, verified timestamp, status, score\n2. **Goal Achievement:** Truth verification table\n3. **Required Artifacts:** Artifact verification table\n4. **Key Link Verification:** Wiring verification table\n5. **Requirements Coverage:** If REQUIREMENTS.md exists\n6. **Anti-Patterns Found:** Scan results table\n7. **Human Verification Required:** Items needing human\n8. **Gaps Summary:** Critical and non-critical gaps\n9. **Recommended Fix Plans:** If gaps_found\n10. **Verification Metadata:** Approach, timing, counts\n\nSee /Users/filipefernandes/.gemini/get-shit-done/templates/verification-report.md for complete template.\n</step>\n\n<step name=\"return_to_orchestrator\">\n**Return results to execute-phase orchestrator.**\n\n**Return format:**\n\n```markdown\n## Verification Complete\n\n**Status:** {passed | gaps_found | human_needed}\n**Score:** {N}/{M} must-haves verified\n**Report:** .planning/phases/{phase_dir}/{phase}-VERIFICATION.md\n\n{If passed:}\nAll must-haves verified. Phase goal achieved. Ready to proceed.\n\n{If gaps_found:}\n### Gaps Found\n\n{N} critical gaps blocking goal achievement:\n1. {Gap 1 summary}\n2. {Gap 2 summary}\n\n### Recommended Fixes\n\n{N} fix plans recommended:\n1. {phase}-{next}-PLAN.md: {name}\n2. {phase}-{next+1}-PLAN.md: {name}\n\n{If human_needed:}\n### Human Verification Required\n\n{N} items need human testing:\n1. {Item 1}\n2. {Item 2}\n\nAutomated checks passed. Awaiting human verification.\n```\n\nThe orchestrator will:\n- If `passed`: Continue to update_roadmap\n- If `gaps_found`: Create and execute fix plans, then re-verify\n- If `human_needed`: Present items to user, collect responses\n</step>\n\n</process>\n\n<success_criteria>\n- [ ] Must-haves established (from frontmatter or derived)\n- [ ] All truths verified with status and evidence\n- [ ] All artifacts checked at all three levels\n- [ ] All key links verified\n- [ ] Requirements coverage assessed (if applicable)\n- [ ] Anti-patterns scanned and categorized\n- [ ] Human verification items identified\n- [ ] Overall status determined\n- [ ] Fix plans generated (if gaps_found)\n- [ ] VERIFICATION.md created with complete report\n- [ ] Results returned to orchestrator\n</success_criteria>\n"
